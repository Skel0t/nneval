fn @max_pool_2(img_mat: Matrix, buf: Buffer, off: i64) -> Matrix {
    let res_mat = make_matrix(buf, off, img_mat.format, img_mat.channels, img_mat.rows / 2, img_mat.cols / 2);
    let img_acc = get_mat_acc(img_mat);

    for r_acc, _v, row, col, chn in iterate_matrix_par(res_mat) {
        let v12 = img_acc.read(2 * row    , 2 * col    , chn);
        let v21 = img_acc.read(2 * row    , 2 * col + 1, chn);
        let v11 = img_acc.read(2 * row + 1, 2 * col    , chn);
        let v22 = img_acc.read(2 * row + 1, 2 * col + 1, chn);

        let val = max(max(v11, v12), max(v21, v22));
        r_acc.write(row, col, chn, val);
    }

    res_mat
}

fn @leaky_relu(img_mat: Matrix, buf: Buffer, off: i64) -> Matrix {
    fn @leaky_relu_x(neg_slope: f32, x: f32) -> f32 {
        if x >= 0.0 {
            x
        } else {
            neg_slope * x
        }
    }

    let res = make_matrix(buf, off, img_mat.format, img_mat.channels, img_mat.rows, img_mat.cols);
    let m_acc = get_mat_acc(img_mat);

    for r_acc, _v, r, c, chn in iterate_matrix_par(res) {
        r_acc.write(r, c, chn, leaky_relu_x(0.01, m_acc.read(r, c, chn)));
    }
    res
}

fn @mkl_relu(img_mat: Matrix, buf: Buffer, off: i64) -> Matrix {
    let res = make_matrix(buf, off, img_mat.format, img_mat.channels, img_mat.rows, img_mat.cols);

    let n = img_mat.channels * img_mat.rows * img_mat.cols;

    mkl_apply_relu(n, bitcast[&[f32]](&(img_mat.buf.data(4 * img_mat.offset))), bitcast[&mut[f32]](&(res.buf.data(4 * res.offset))));
    res
}

fn @max(x: f32, y: f32) -> f32 {
    select(x > y, x, y)
}

// Rewrites CHW and to HWC by copying
fn @chw_to_hwc(img_mat: Matrix, buf: Buffer, off: i64) -> Matrix {
    let res = make_matrix(buf, off, MemoryFormat::HWC, img_mat.channels, img_mat.rows, img_mat.cols);

    let img_acc = get_mat_acc(img_mat);

    for res_acc, _v, row, col, chn in iterate_matrix_par(res) {
        res_acc.write(row, col, chn, img_acc.read(row, col, chn));
    }

    res
}

fn @nearest(img_mat: Matrix, buf: Buffer, off: i64) -> Matrix {
    let res_mat = make_matrix(buf, off, img_mat.format, img_mat.channels, img_mat.rows * 2, img_mat.cols * 2);

    let img_acc = get_mat_acc(img_mat);

    for res_acc, _v, row, col, chn in iterate_matrix_par(res_mat) {
        res_acc.write(row, col, chn, img_acc.read(row / 2, col / 2, chn));
    }

    res_mat
}

// TODO: Change f32's to own type and use sizeof[type]() instead of 4
// Only supporting stride of 1

fn @cat_conv(ksize: i32, out_channels: i32, in_channels: i32, flattened_kernels: Matrix, biases: fn(i32) -> f32, in_rows: i32, in_cols: i32, img_acc: AccM, use_bias: bool, buf: Buffer, off: i64, off_res: i64) -> Matrix {
    // insize == outsize if padding == ksize / 2.0 - 1
    let padding    = ksize / 2;
    let out_width  = (in_cols + 2 * padding - ksize) + 1;
    let out_height = (in_rows + 2 * padding - ksize) + 1;

    let im2col_mat = im2col(ksize, out_width, out_height, in_cols, in_rows, in_channels, img_acc, padding, buf, off);
    let prod       = mkl_matmul(flattened_kernels, im2col_mat, buf, off_res);

    if use_bias {
        for row in range(0, prod.rows) {
            let offset = 4 * (prod.offset + (row * prod.cols) as i64);
            mkl_add_constant(/*n*/ prod.cols, /*a*/ bitcast[&[f32]](&(prod.buf.data(offset))),
                             /*val*/ biases(row), /*res*/ bitcast[&mut[f32]](&(prod.buf.data(offset))));    // 1 channel per row
        }
    }

    make_matrix(buf, off_res, MemoryFormat::CHW, out_channels, out_height, out_width)
}
