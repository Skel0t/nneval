fn @make_conv_matrix(kernel: Matrix, img_mat: Matrix, buf: Buffer, off: i64) -> Sparse {
    let width    = img_mat.cols;
    let height   = img_mat.rows;
    let channels = img_mat.channels;
    let format   = img_mat.format;

    let ksizeh_r = kernel.rows / 2;
    let ksizeh_c = kernel.cols / 2;

    let mat   = make_sparse(buf, off, width * height, kernel.cols * kernel.rows * kernel.channels);
    let m_acc = get_sparse_acc(mat);
    let k_acc = get_mat_acc(kernel);

    for j in parallel(0, 0, height) {
        for i in range(0, width) {
            let s_row = j * width + i;
            for r in unroll(-ksizeh_r, ksizeh_r+1) {
                for c in unroll(-ksizeh_c, ksizeh_c+1) {
                    let im_row = j + r;
                    let im_col = i + c;

                    let k_row = r + ksizeh_r;
                    let k_col = c + ksizeh_c;

                    let s_col = (k_row * kernel.cols + k_col) * kernel.channels;
                    for channel in unroll(0, channels) {
                        if im_row < 0 || im_col < 0 || im_col >= width || im_row >= height {
                            m_acc.write(s_row, s_col + channel, 0, 0); // padding with 0s s.t. image size at start and end is the same
                            continue()
                        }
                        let mut index : i32;
                        match format {
                            MemoryFormat::HWC => { index = (im_row * width + im_col) * channels + channel; },
                            MemoryFormat::CHW => { index = (im_row * width + im_col) + channel * width * height; }
                        }
                        m_acc.write(s_row, s_col + channel, k_acc.read(k_row, k_col, channel), index);
                    }
                }
            }
        }
    }
    mat
}


fn @convolute(kernel: Matrix, img_mat: Matrix, bias: f32, use_bias: bool, buf: Buffer, off: i64, off_result: i64) -> () {
    let m = reshape_matrix(img_mat, img_mat.rows * img_mat.cols, 1);    // Doesn't really do anything, since m is just used bitcast. But it's necessary to have the right dimensions for multiplication.

    let conv = make_conv_matrix(kernel, img_mat, buf, off);
    let prod = sparse_mult(conv, m, buf, off_result);

    if use_bias {
        for acc, v, r, c, chn in iterate_matrix_par(prod) {
            acc.write(r, c, chn, v + bias);
        }
    }
}

fn @conv2d(out_channels: i32, kernels: fn(i32) -> Matrix, biases: fn(i32) -> f32, img_mat: Matrix, use_bias: bool, buf: Buffer, off: i64) -> Matrix {
    let width  = img_mat.cols;
    let height = img_mat.rows;

    let result_size = width as i64 * height as i64;
    let sparse_size = 2 * (width as i64) * (height as i64) * (kernels(0).cols as i64) * (kernels(0).rows as i64) * (kernels(0).channels as i64);

    for i in range(0, out_channels) {
        let buf_off  = off + i as i64 * result_size + sparse_size;
        convolute(kernels(i), img_mat, biases(i), use_bias, buf, off, buf_off);
    }

    make_matrix(buf, off + sparse_size, MemoryFormat::CHW, out_channels, height, width)
}

// BIG TODO
/*fn @max_pool(img_mat: Matrix, ksize: i32, channels:i32) -> Matrix {
    let buffer = alloc(0, 4 * img_mat.cols as i64 * img_mat.rows as i64 / (ksize * ksize) as i64);

    let acc     = bitcast[&mut[f32]](buffer.data);
    let img_acc = bitcast[&[f32]](img_mat.buf.data);
    for i in unroll(0, channels) {
        for y in range(0, img_mat.rows / 2) {
            for x in range(0, img_mat.cols / (channels * 2)) {
                let v11 = img_acc((i * img_mat.cols * img_mat.rows / channels) +  2*y    * img_mat.cols / channels + 2*x);
                let v12 = img_acc((i * img_mat.cols * img_mat.rows / channels) +  2*y    * img_mat.cols / channels + 2*x+1);
                let v21 = img_acc((i * img_mat.cols * img_mat.rows / channels) + (2*y+1) * img_mat.cols / channels + 2*x);
                let v22 = img_acc((i * img_mat.cols * img_mat.rows / channels) + (2*y+1) * img_mat.cols / channels + 2*x+1);

                let val = max(max(v11, v12), max(v21, v22));
                acc((i * img_mat.cols * img_mat.rows / (channels * 4)) + y * (img_mat.cols / (channels * 2)) + x) = val;
            }
        }
    }
    release(img_mat.buf);
    make_matrix(buffer, 0, img_mat.rows / 2, img_mat.cols / 2)
}*/

fn @leaky_relu(img_mat: Matrix, buf: Buffer, off: i64) -> Matrix {
    fn @leaky_relu_x(neg_slope: f32, x: f32) -> f32 {
        if x >= 0.0 {
            x
        } else {
            neg_slope * x
        }
    }

    let res = make_matrix(buf, off, img_mat.format, img_mat.channels, img_mat.rows, img_mat.cols);
    let m_acc = get_mat_acc(img_mat);

    for r_acc, _v, r, c, chn in iterate_matrix_par(res) {
        r_acc.write(r, c, chn, leaky_relu_x(0.01, m_acc.read(r, c, chn)));
    }
    res
}

fn @max(x: f32, y: f32) -> f32 {
    select(x > y, x, y)
}

// Rewrites CHW and to HWC by copying
fn @make_interleaved(img_mat: Matrix, buf: Buffer, off: i64) -> Matrix {
    let res = make_matrix(buf, off, MemoryFormat::HWC, img_mat.channels, img_mat.rows, img_mat.cols);

    let img_acc = get_mat_acc(img_mat);

    for res_acc, _v, row, col, chn in iterate_matrix_par(res) {
        res_acc.write(row, col, chn, img_acc.read(row, col, chn));
    }

    res
}

fn @nearest(img_mat: Matrix, buf: Buffer, off: i64) -> Matrix {
    print_string("nearest\n");
    let res_mat = make_matrix(buf, off, img_mat.format, img_mat.channels, img_mat.rows * 2, img_mat.cols * 2);

    let res_acc = get_mat_acc(res_mat);
    let img_acc = get_mat_acc(img_mat);

    for res_acc, _v, row, col, chn in iterate_matrix_par(res_mat) {
        res_acc.write(row, col, chn, img_acc.read(row / 2, col / 2, chn));
    }

    res_mat
}

fn conv_with_im2col(ksize: i32, out_channels: i32, flattened_kernels: Matrix, biases: fn(i32) -> f32, img_mat: Matrix, use_bias: bool, buf: Buffer, off: i64, off_res: i64) -> Matrix {
    let width  = img_mat.cols;
    let height = img_mat.rows;

    let im2col_mat = im2col(ksize, img_mat, ksize / 2, buf, off);
    let prod       = matmul(flattened_kernels, im2col_mat, buf, off_res);

    if use_bias {
        for acc, v, row, col, chn in iterate_matrix_par(prod) {
            acc.write(row, col, chn, v + biases(row));  // 1 channel per row
        }
    }

    make_matrix(buf, off_res, MemoryFormat::CHW, out_channels, height, width)
}

// TODO: Change f32's to own type and use sizeof[type]() instead of 4
fn im2col(ksize: i32, img_mat: Matrix, padding: i32, buf: Buffer, off: i64) -> Matrix {
    let img_s  = img_mat.cols * img_mat.rows;

    let bc = bitcast[&mut[f32]](buf.data);

    let res_mat = make_matrix(buf, off, MemoryFormat::CHW, 1, img_mat.channels * ksize * ksize, img_mat.rows * img_mat.cols);

    for img_acc, _val, row, col, chn in iterate_matrix_par(img_mat) {
        let mut base_row = ksize * ksize * img_s * chn;
        let base_col = row * img_mat.cols + col;

        let p_row = row - padding;
        let p_col = col - padding;

        for y in unroll(0, ksize) {
            for x in unroll(0, ksize) {
                let h = p_row + y;
                let w = p_col + x;
                if h < 0 || w < 0 || h >= img_mat.rows || w > img_mat.cols {
                    bc(off + (base_row + base_col) as i64) = 0;
                } else {
                    bc(off + (base_row + base_col) as i64) = img_acc.read(h, w, chn);
                }

                base_row += img_s;
            }
        }
    }

    res_mat
}
