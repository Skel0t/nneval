fn @make_conv_matrix(kernel: Matrix, im_width: i32, im_height: i32, channels: i32, buf: Buffer, off: i64) -> Sparse {
    let m = make_sparse(buf, off, im_width * im_height, kernel.cols * kernel.rows);
    let m_acc = get_sparse_acc(m);
    let k_acc = get_mat_acc(kernel);

    // Not very efficient, can maybe only set the ones to 0 that arent set in the loop below?
    for _acc, _v, _i, r, c in iterate_sparse(m) {
        m_acc.write(r, c, 0.0, 0);
    }

    let ksizeh_r = kernel.rows / 2;
    let ksizeh_c = kernel.cols / (2 * channels);

    let stride_y = im_width * channels;

    for j in parallel(0, 0, im_height) {
        for i in range(0, im_width) {
            let s_row = j * im_width + i;
            for r in unroll(-ksizeh_r, ksizeh_r+1) {
                let im_row = j + r;
                if im_row < 0 || im_row >= im_height { continue() } // padding with 0s s.t. image size at start and end is the same
                for c in unroll(-ksizeh_c, ksizeh_c+1) {
                    let im_col = (i + c) * channels;
                    if im_col < 0 || im_col >= stride_y { continue() } // padding with 0s s.t. image size at start and end is the same
                    let k_row = r + ksizeh_r;
                    let k_col = (c + ksizeh_c) * channels;
                    let s_col = k_row * kernel.cols + k_col;
                    for channel in unroll(0, channels) {
                        m_acc.write(s_row, s_col + channel, k_acc.read(k_row, k_col + channel), im_row * stride_y + im_col + channel);
                    }
                }
            }
        }
    }
    m
}
// Accessor fÃ¼r matrix mit channel machen, um diese routine mit non interleaved channel easy zu benutzen


// Image needs to be channel-interleaved (e.g. RGBRGBRGB), same for kernel weights
fn @convolute(kernel: Matrix, channels: i32, img_mat: Matrix, width: i32, height: i32, bias: f32, use_bias: bool, buf: Buffer, off: i64, off_res: i64) -> () {
    let m = reshape_matrix(img_mat, img_mat.rows * img_mat.cols, 1);    // Image as column-vector, interleaved column style

    let conv = make_conv_matrix(kernel, width, height, channels, buf, off);
    let prod = sparse_mult(conv, m, buf, off_res);    // Fails here with leaky_relu parallelized, WHY?

    if use_bias {
        for acc, v, r, c in iterate_matrix(prod) {
            acc.write(r, c, v + bias);
        }
    }
}

fn @conv2d(in_channels: i32, out_channels: i32, kernels: fn(i32) -> Matrix, biases: fn(i32) -> f32, img_mat: Matrix, use_bias: bool, buf: Buffer, off: i64) -> Matrix {
    let width  = img_mat.cols / in_channels;
    let height = img_mat.rows;

    let result_size = width as i64 * height as i64;
    let sparse_size = 2 * width as i64 * height as i64 * kernels(0).cols as i64 * kernels(0).rows as i64;

    for i in range(0, out_channels) {
        let buf_off  = off + i as i64 * result_size + sparse_size;
        convolute(kernels(i), in_channels, img_mat, width, height, biases(i), use_bias, buf, off, buf_off);
    }

    make_matrix(buf, off + sparse_size, height, width * out_channels)
}

// Image by channels separated RRRRRR...GGGGGG....BBBBBB
fn @max_pool(img_mat: Matrix, ksize: i32, channels:i32) -> Matrix {
    // TODO dont use alloc
    let buffer = alloc(0, 4 * img_mat.cols as i64 * img_mat.rows as i64 / (ksize * ksize) as i64);

    // TODO: Use accessors
    let acc     = bitcast[&mut[f32]](buffer.data);
    let img_acc = bitcast[&[f32]](img_mat.buf.data);
    for i in unroll(0, channels) {
        for y in range(0, img_mat.rows / 2) {
            for x in range(0, img_mat.cols / (channels * 2)) {
                let v11 = img_acc((i * img_mat.cols * img_mat.rows / channels) +  2*y    * img_mat.cols / channels + 2*x);
                let v12 = img_acc((i * img_mat.cols * img_mat.rows / channels) +  2*y    * img_mat.cols / channels + 2*x+1);
                let v21 = img_acc((i * img_mat.cols * img_mat.rows / channels) + (2*y+1) * img_mat.cols / channels + 2*x);
                let v22 = img_acc((i * img_mat.cols * img_mat.rows / channels) + (2*y+1) * img_mat.cols / channels + 2*x+1);

                let val = max(max(v11, v12), max(v21, v22));
                acc((i * img_mat.cols * img_mat.rows / (channels * 4)) + y * (img_mat.cols / (channels * 2)) + x) = val;
            }
        }
    }
    release(img_mat.buf);
    make_matrix(buffer, 0, img_mat.rows / 2, img_mat.cols / 2)
}

fn @leaky_relu(img_mat: Matrix) -> Matrix {
    for acc, v, r, c in iterate_matrix(img_mat) { // TODO: Can't use par here, why?
        acc.write(r, c, leaky_relu_x(0.01, v));
    }
    img_mat
}

fn @max(x: f32, y: f32) -> f32 {
    select(x > y, x, y)
}

fn @leaky_relu_x(neg_slope: f32, x: f32) -> f32 {
    if x >= 0.0 {
        x
    } else {
        neg_slope * x
    }
}

fn @make_interleaved(img_mat: Matrix, channels: i32, buf: Buffer, off: i64) -> Matrix {
    let accC = bitcast[&mut[f32]](buf.data);
    let accB = bitcast[&   [f32]](img_mat.buf.data);

    // TODO: Use accessors and matrix iteration
    for y in range(0, img_mat.rows) {
        for x in range(0, img_mat.cols / channels) {
            for i in unroll(0, channels) {
                accC(off + (y * img_mat.cols + x * channels + i) as i64) = accB(img_mat.offset + (y * img_mat.cols / channels + x + i * img_mat.cols * img_mat.rows / channels) as i64);
            }
        }
    }

    make_matrix(buf, off, img_mat.rows, img_mat.cols)
}

fn @nearest(img_mat: Matrix, channels: i32, buf: Buffer, off: i64) -> Matrix {
    let res_mat = make_matrix(buf, off, img_mat.rows * 2, img_mat.cols * 2);
    let accR = get_mat_acc(res_mat);
    let accI = get_mat_acc(img_mat);

    // TODO: Use Matrix iteration
    for y in range(0, res_mat.rows) {
        for x in range(0, res_mat.cols / channels) {
            for i in unroll(0, channels) {
                accR.write(y, (channels * x) + i, accI.read(y / 2, channels * (x / 2) + i));
            }
        }
    }
    res_mat
}
